---
title: "2026-01-22 Hacker News Top Articles and Its Summaries"
date: 2026-01-22T17:01:02+08:06
draft: false
tags:
  - hackernews
---

## 1. [GPTZero finds 100 new hallucinations in NeurIPS 2025 accepted papers](https://news.ycombinator.com/item?id=46720395)

**Total comment counts : 65**

### Summary

 GPTZero analyzed 4,841 NeurIPS 2025 papers and found hundreds of hallucinated citations, with 100 confirmed hallucinations across 51 papers not flagged by reviewers. Using its Hallucination Check tool, the study shows AI-driven submissions, paper mills, and publication pressure straining the peer-review process. Despite a 24.52% main-track acceptance rate, these papers beat out about 15,000 other submissions while containing hallucinations. The authors frame this as a systemic vulnerability in peer review, not fault of individual organizers or reviewers.

### Overall Comments Summary

- Main point: The thread discusses the risks of AI-generated hallucinations and misattributions in scholarly papers (e.g., incorrect author lists and references) and their implications for reproducibility, trust, and the publish-or-perish ecosystem.
- Concern: The main worry is that such hallucinations and fabrication could erode scientific integrity, amplify misleading claims, and incentivize bad behavior unless checks and policies tighten.
- Perspectives: Some view the errors as minor and solvable with better checks and reproducibility reporting, while others urge stronger policies, sanctions, and automated citation verification amid concerns about reviewer workload and incentives.
- Overall sentiment: Mixed

## 2. [Show HN: isometric.nyc – giant isometric pixel art map of NYC](https://news.ycombinator.com/item?id=46721802)

**Total comment counts : 59**

### Summary

 error

### Overall Comments Summary

- Main point: The discussion analyzes an AI-assisted isometric NYC map project, weighing AI-generated output against hand-crafted work and examining workflow, costs, and artistic quality.
- Concern: The project risks appearing AI-generated rather than handmade, raising questions about authenticity and framing, alongside practical issues like costs and technical reliability.
- Perspectives: The thread presents a range of views from praise of the AI-enabled workflow and fusion of art and tech to defense of handmade craftsmanship and critique of framing, ethics, and economics.
- Overall sentiment: Mixed

## 3. [Qwen3-TTS family is now open sourced: Voice design, clone, and generation](https://news.ycombinator.com/item?id=46719229)

**Total comment counts : 19**

### Summary

 error

### Overall Comments Summary

- Main point: A discussion about trying and evaluating Qwen3-TTS voice cloning, sharing demos and experiments, and assessing its potential uses and limitations.
- Concern: The model’s outputs are highly inconsistent and can be misused for impersonation or deception, alongside practical barriers to running it locally or on different platforms.
- Perspectives: Views range from excitement about its potential for audiobooks and remastering old audio to skepticism about reliability, ethics and politics of the company, and technical/hardware hurdles.
- Overall sentiment: Mixed

## 4. ['Askers' vs. 'Guessers' (2010)](https://news.ycombinator.com/item?id=46717960)

**Total comment counts : 10**

### Summary

 This brief mentions “Forbidden Details” related to a Varnish cache server. It identifies a cache node named cache-sjc10040-SJC and includes the numbers 1769118201 and 3088553232, suggesting restricted information connected to that Varnish cache server.

### Overall Comments Summary

- Main point: The discussion analyzes the "Ask vs. Guess" culture framework, sharing personal benefits, criticisms, and debates about its usefulness in communication.  
- Concern: Labeling people as either Askers or Guessers can oversimplify interactions, overlook context and power dynamics, and potentially damage relationships.  
- Perspectives: Some users find the framework illuminating and helpful for cross-cultural communication, while others worry it’s caricature-like, unproven, or broadly inaccurate.  
- Overall sentiment: Mixed

## 5. [CSS Optical Illusions](https://news.ycombinator.com/item?id=46722570)

**Total comment counts : 6**

### Summary

 Former Child A’s collection comprises 50+ CSS/HTML optical illusions, mostly CSS, showcased on CodePen. The pieces use gradients, pseudo-elements, and blend modes, with many requiring hover or mouse position to reveal the effect. Highlights include the Poggendorff illusion, Münsterberg arch, gradient-based tricks that mimic real gradients, and color/brightness tricks where identical shades look different due to context. The collection also explores brain colorization, shadow/shading quirks, and checkered/halo illusions, illustrating how perception can be deceived by simple CSS techniques.

### Overall Comments Summary

- Main point: The discussion centers on extinction illusions (dots that appear or disappear) and related optical phenomena, with sources, demos, and debate about their nature and potential UI uses.
- Concern: The main worry is whether these effects are genuine optical illusions or merely clever CSS demonstrations, which could limit their practicality or reliability.
- Perspectives: Opinions vary from praising the demos as cool, educational illusions with UI potential to skeptical views that they are mainly demonstrations rather than true illusions.
- Overall sentiment: Mixed

## 6. [Compiling Scheme to WebAssembly](https://news.ycombinator.com/item?id=46663200)

**Total comment counts : 2**

### Summary

 Bob, my long-running open-source project, is a suite of Scheme implementations in Python (interpreter, compiler, VM). Celebrating 15 years, it later gained a C++ VM with a custom mark-and-sweep GC, and now a WasmCompiler that compiles Scheme to WebAssembly text for binary execution. Key challenges include representing Scheme objects in WASM GC: boxed refs, nullable refs, an i31 trick for numbers, and symbol/string interning in linear memory. The write procedure is implemented in WASM text. Total code is about 1000 LOC, using wasm-tools and Node.js.

### Overall Comments Summary

- Main point: There is interest in a very small language that compiles to WebAssembly for in-browser use, ideally with a wasm footprint under 1 Mb.
- Concern: Whether it is realistically feasible to achieve a language that compiles to wasm with such an ultra-small size.
- Perspectives: Opinions range from praise for tiny toolchains like uLisp to recognition of Lua or Rhai as in-browser wasm options, while longing for a language that compiles directly to wasm within a 1 Mb footprint.
- Overall sentiment: Cautiously optimistic

## 7. [Show HN: CLI for working with Apple Core ML models](https://news.ycombinator.com/item?id=46724565)

**Total comment counts : 0**

### Summary

 The article describes a native macOS command-line interface for Apple Core ML models. It lets you inspect, run inference, benchmark, and manage Core ML models without Xcode or Python. Requirements: macOS 13+ and Swift 5.9+. Features include viewing model structure/metadata, JSON outputs for scripting/CI/CD, image classification, saving results, selecting compute device, batch processing directories, measuring latency, custom iterations, and converting models (.mlmodel to .mlmodelc). Supports numeric tensor inputs via JSON arrays and input.json, emits CSV results, and is MIT-licensed with contributions welcome; download from GitHub Releases.

## 8. [Recent discoveries on the acquisition of the highest levels of human performance](https://news.ycombinator.com/item?id=46722853)

**Total comment counts : 10**

### Summary

 error

### Overall Comments Summary

- Main point: The discussion argues that the seeming gap between early elite performers and later top performers can be explained by Berkson's paradox, regression toward the mean, and other randomness-driven factors, challenging simple narratives about talent.
- Concern: Misinterpreting these patterns could fuel simplistic, marketing-driven claims about “the very best” and mislead aspirants who don’t follow the same trajectory.
- Perspectives: Some see the patterns as evidence for selection effects and non-stationarity (Berkson's paradox), while others highlight randomness, differential resources, and the risks of overinterpreting talent studies.
- Overall sentiment: Mixed

## 9. [Tree-sitter vs. Language Servers](https://news.ycombinator.com/item?id=46719899)

**Total comment counts : 17**

### Summary

 Tree-sitter is a parser generator that creates fast, error-tolerant parsers for languages, enabling faithful syntax highlighting and offering a query language to locate syntax objects. A language server implements the Language Server Protocol, analyzing code with access to runtime and toolchain data to provide features like go-to-definition and completions, and can also power syntax highlighting (though it can be slower and more complex). The author favors Tree-sitter for highlighting but notes that a language server’s deeper semantic capabilities (e.g., rust-analyzer signaling mutable references) can be useful. The post highlights practical, observable differences between the two.

### Overall Comments Summary

- Main point: The discussion weighs using a language server for syntax highlighting versus tree-sitter, and whether a hybrid approach offers the best balance of latency, memory usage, and accuracy.
- Concern: Relying on a language server for highlighting can introduce latency, UI flicker, and memory overhead, plus complexity and potential divergence bugs.
- Perspectives: Opinions vary from favoring language servers for semantically correct highlighting and navigation, to preferring tree-sitter for fast, synchronous syntax coloring, to blending both approaches to combine their strengths.
- Overall sentiment: Mixed

## 10. [Launch HN: Constellation Space (YC W26) – AI for satellite mission assurance](https://news.ycombinator.com/item?id=46721933)

**Total comment counts : 5**

### Summary

 Three veterans from SpaceX, Blue Origin, and NASA describe a predictive RF-link health system for satellite constellations. Instead of reactive rerouting, the system ingests ~100k messages/sec from satellites, ground stations, weather radar, IoT humidity sensors, and space-weather monitors; runs real-time physics-based link-budget models with ITU standards; and adds federated ML. Federated learning enables cross-constellation knowledge without sharing raw data, enabling transfer learning across LEO/MEO/GEO. The model predicts most link failures 3–5 minutes ahead with >90% accuracy, enabling proactive rerouting. It’s containerized (Docker/Kubernetes) and deployable on on-prem, GovCloud, or commercial clouds; in defense/commercial pilots.

### Overall Comments Summary

- Main point: The discussion centers on a demo video and the reliability of the company's telemetry ingestion, with side questions about funding, hiring, and potential involvement in orbital weapon systems.
- Concern: The main worry is that any delay or loss in telemetry data will undermine the system's reliability and the demo's credibility.
- Perspectives: Opinions range from impressed and curious about hiring and raising funds to skeptical or provocative about potential work on orbital weapon systems.
- Overall sentiment: Mixed

