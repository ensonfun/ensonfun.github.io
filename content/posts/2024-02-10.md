---
title: "2024-02-10 Hacker News Top Articles and Its Summaries"
date: 2024-02-10T19:01:02+08:06
draft: false
tags:
  - hackernews
---

## 1. [Almost every infrastructure decision I endorse or regret](https://news.ycombinator.com/item?id=39313623)

**Total comment counts : 74**

### Summary

 The author of the article shares their experiences and recommendations regarding various infrastructure decisions for startups. They endorse using AWS over Google Cloud due to better support and stability. They recommend using EKS for Kubernetes clusters unless cost is a concern. They regret using EKS managed addons and suggest using helm charts instead. They endorse using managed databases like RDS and Redis as a cache. They also endorse using ECR over quay.io for hosting and recommend using VPNs for simplicity, despite the cost. They endorse using AFT for automating account setup and tagging. Lastly, they endorse using automated reminders and templates for post-mortem procedures during incidents.

### Top 1 Comment Summary

 The article argues that the cost of using managed databases like Amazon RDS is significantly higher compared to running a self-hosted SQL Server cluster. The author finds the cost of RDS to be unrealistically expensive and states that the markup is enough to cover various expenses, including colocation rack, AWS Direct Connects, servers, SAN, SQL Server licenses, maintenance contracts, and a full-time in-house DBA. The author suggests that once the savings from markup can pay for one or more full-time employees, it may be more cost-effective to hire in-house staff rather than continue scaling up with RDS. The article encourages reevaluating choices when the costs with RDS reach the level of paying a full-time engineer.

### Top 2 Comment Summary

 The author of the article expresses satisfaction with their choice of picking AWS and appreciates their human-based customer service, in contrast to Google's robot-based customer service. Though the author acknowledges that he may be oversimplifying and does not imply anything is wrong, he finds this difference amusing.

## 2. [Building the DirectX shader compiler better than Microsoft?](https://news.ycombinator.com/item?id=39324800)

**Total comment counts : 21**

### Summary

 The article discusses the state of Microsoft's DirectX shader compiler and the efforts to improve it for game developers. The author mentions the creation of an experimental graphics API called sysgpu using Zig, which aims to support various backends such as Metal, Vulkan, Direct3D, and OpenGL. The article also explains the transition from the FXC compiler to the new DXC compiler with the release of Direct3D 12 and Shader Model 6.0. It highlights the issues with suboptimal code generation in the FXC compiler and the improvements made in DXC. The article mentions the different compute architectures and requirements of GPUs from vendors like Intel, AMD, and NVIDIA, and how Microsoft works with these vendors to bridge the gap between frontend APIs and hardware. The article also discusses the shift from DirectX Byte Code (DXBC) to DXIL bytecode as the format consumed by DirectX 12 driver manufacturers. However, it notes that DXIL, like DXBC, is an undocumented bytecode format. Overall, the article highlights the challenges and complexities of the shader compiler landscape in game development.

### Top 1 Comment Summary

 The article discusses the challenges and complications of cross-3D-API shader compilation. It explains that the issue is not limited to just DirectX 3D (D3D) and Microsoft, but also affects other 3D APIs. The author mentions that it is currently not possible to cross-compile Metal shaders from a Linux host, only from macOS or Windows. The article concludes by mentioning the potential significance of Zig, a programming language, being utilized as a cross-3D-API shader compiler, stating that it could be a major development in computer graphics.

### Top 2 Comment Summary

 The article states that in the Godot game engine, support for Direct3D 12 will be made optional. This decision is due to the reliance on the proprietary dxil.dll library from the DirectX Shader Compiler, which goes against the project's mission of not shipping proprietary software.

## 3. [BirdLingo: A birdsong learning game](https://news.ycombinator.com/item?id=39323893)

**Total comment counts : 24**

### Summary

 The article discusses the release of demo version 2 of BirdLingo, an elearning game designed to help users recognize bird songs. The update includes a hint button for difficult birds and the ability to exit habitats. Users have provided positive feedback, with some expressing interest in a more comprehensive version of the game. The game is praised for its educational value and its ability to teach users about different types of birdsongs. The article also mentions the possibility of including Japanese birds in a future version of the game. The author of the article offers to review the game in a YouTube video and expresses appreciation for the game's ability to fulfill the desire to birdwatch without requiring extensive knowledge of bird calls.

### Top 1 Comment Summary

 The article notes that while language localization has been mentioned, the author believes that species localization is also important. They mention that none of the birds presented to them are native to their area and suggest that it would be beneficial to focus users on birdsongs they are likely to hear in their specific region.

### Top 2 Comment Summary

 The author enjoyed spending time learning to recognize bird sounds, although they do not consider themselves to be a dedicated birdwatcher. They mention that it would be interesting to determine which country the birds they were listening to are from, and note that Australian birds have a distinctive and amusing sound.

## 4. [Postgres as queue](https://news.ycombinator.com/item?id=39315833)

**Total comment counts : 27**

### Summary

 The article discusses the use of Postgres-as-queue as a simpler alternative to ad-hoc SNS/PubSub/Kafka architectures. The main concern with this approach is the potential increase in database load. However, the article provides a reasonable example to show that queue usage should not introduce much extra load in many cases. The example used is from the energy industry, where a task involves queuing a task to write a customer's meter reading and update their account balance. The article also provides code snippets and tips for implementing the queue system using Postgres.

### Top 1 Comment Summary

 This article discusses the features of Postgres that make it a great option for queuing tasks. The author highlights four key features, including the ability to use LISTEN to be notified of changes, NOTIFY to send events to listeners, the use of SKIP LOCKED for efficient selection, and the use of partial indexes to select rows in a particular state. The article describes how backend workers can use these features to create a state machine and transition units of work from one status to another. The author also mentions the importance of having a lease_expire column to handle failed workers. Overall, the article argues that using Postgres as a queue is a good choice compared to other options like SQS or ActiveMQ.

### Top 2 Comment Summary

 The author decided to use their Postgres database for worker queues on their website, instead of using more specific queue solutions. They mentioned that there are 10,000 jobs per day, which does not add any additional load. They believe that using their database is a simple and efficient solution, as they know how it works, can easily extend it, and it does not complicate local development. They also mentioned that there is no need for new infrastructure, which could potentially introduce another point of failure. The author plans to switch to a different solution if they have millions of users, but for now, they are satisfied with the Postgres database solution, which only took a day to implement.

## 5. [OPML is underrated](https://news.ycombinator.com/item?id=39324847)

**Total comment counts : 14**

### Summary

 The article discusses the resurgence of personal blogs and the rise of the "small web" in response to the negative aspects of major platforms. The author highlights the importance of open web standards, specifically RSS, which allows users to curate their own information streams and have more control over the content they consume. However, managing and organizing RSS feeds can be challenging, which is where OPML (an outliner format) comes in. OPML allows users to store and manage a list of feed subscriptions in a single file, making it easier to organize, migrate, and share feeds across different platforms. The author also emphasizes the potential for OPML to improve the ecosystem of the small web by creating a recommendation system based on conscious curation. Additionally, the author mentions the ability to use an XSL stylesheet to display the OPML file with added context or descriptions. Overall, the article encourages readers to create their own blogroll using OPML and share their interests, as it can help foster connections and bring back a sense of community.

### Top 1 Comment Summary

 The article discusses the contributions of Dave Winer, an underappreciated figure in the tech community. In 2000, Winer developed OPML as a way to share lists and used an outliner to compose his weblog, demonstrating the connection between structure and writing. Despite his initial cantankerous demeanor, the author recalls a positive encounter with Winer and their collaboration in 2003 to create a Comments namespace for RSS 2.0. The article also emphasizes the value of both OPML and RSS as standards for maintaining the free flow of information on the web, created by one passionate individual rather than a committee or organization.

### Top 2 Comment Summary

 The author is frustrated with the increasing difficulty of finding the RSS feed for podcasts. They believe that without an RSS feed, it is not a true podcast. The author dislikes the control exerted by certain platforms over the podcasting medium.

## 6. [Espressif ESP32: Breaking HW AES with Power Analysis (2023)](https://news.ycombinator.com/item?id=39322388)

**Total comment counts : 5**

### Summary

 The article discusses side channel analysis (SCA) attacks, which are used to extract the secret key of cryptographic engines in modern devices. These attacks exploit side channels such as timing, power, and electromagnetic leaks to obtain information about the secret key. The article mentions that even strong cryptography algorithms like AES are susceptible to SCA attacks if no countermeasures are in place. The article highlights the discovery by Ledger Dojon that the key used by the flash encryption feature of the ESP32 chip can be extracted through a power analysis attack. The article also mentions other examples of SCA attacks on devices like the iPhone, Xbox 360, and ARMv8 Cryptographic Extensions. The article further discusses the process of communicating with the hardware AES engine of the ESP32 chip and the use of a custom board and power analysis setup to measure the current of the chip. The article concludes by mentioning the use of Riscure's FiPy Python framework for controlling the setup during the acquisition of multiple encryption operations.

### Top 1 Comment Summary

 The article discusses the reliance of unknown key extraction on knowing when the AES engine is engaged. The authors use a trigger on pin 26 of the ESP32 to inform their acquisition hardware when the AES engine is running, allowing them to focus on the sample that contains the most information about the key bits. In a real-world attack, this information would not be available, making the attack significantly more difficult.

### Top 2 Comment Summary

 The article mentioned lacks informative content and fails to explain the theory or process behind the tools and guides used. The author states that there was no discussion of the AES configuration deployed and its impact on the process. The provided links are considered more helpful in this regard.

## 7. [Lessons from a fountain pen addict](https://news.ycombinator.com/item?id=39301948)

**Total comment counts : 33**

### Summary

 The article discusses the writer's experience in the world of stationery, particularly with writing instruments. The author shares advice for beginners and seasoned hobbyists, emphasizing the importance of understanding personal preferences and individual compatibility with different brands. The author also highlights the influence of community reviews, the impact of limited edition releases, and the role of quality control in shaping one's opinion of a pen.

### Top 1 Comment Summary

 The article suggests two important lessons about using pens. Firstly, it is recommended to clean a pen thoroughly before refilling or replacing the cartridge when it goes dry. Secondly, if a pen is not going to be used for an extended period of time (weeks or months), it is advised to empty, flush, and dry it thoroughly before storing it. The article also recommends trying an italic or stub nib and provides links to resources on Chancery Italic and handwriting repair.

### Top 2 Comment Summary

 The author of the article has been exclusively using fountain pens for two years. They believe that fountain pens are not overhyped and are worth the investment. The author recommends the Pilot Metropolitan, Lamy Safari, and Platinum Preppy pens, as well as Lamy, Platinum, Pilot, and Noodler's ink. They also mention owning multiple Pilot Metropolitans, Platinum Preppies, a Lamy Safari, and several Indian Parkers. The author states that these pens are affordable and reliable options.

## 8. [LubeLogger: Self-hosted, open-source vehicle service records and tracker](https://news.ycombinator.com/item?id=39323601)

**Total comment counts : 20**

### Summary

 This article introduces a self-hosted, open-source vehicle service records and maintenance tracker called "Vehicle Service Records and Maintenance Tracker." The article encourages readers to visit the website, which is https://lubelogger.com, and support the project through subscribing on Patreon or making a donation. The goal of the tracker is to provide an alternative to homemade spreadsheets or shoeboxes full of receipts for managing vehicle maintenance. The article also mentions that there are screenshots available for previewing the tracker and a live demo that resets every 20 minutes. Instructions on how to access the live demo and suggested examples are provided.

### Top 1 Comment Summary

 The article mentions the absence of a "Done" option in the project planning screen. The author currently uses an excel sheet for their own project planning. They also track fuel consumption by calculating the average of the last X fill-ups, where X represents the oil change interval. This helps identify performance issues. Additionally, the author organizes parts replacement by system and specific items to make them easier to find in maintenance records. They appreciate the overall effort of the project discussed in the article.

### Top 2 Comment Summary

 The article expresses a desire for a tool that can track maintenance for various machines, such as lathes and pressure washers. It suggests features like reminders for regular maintenance, recording oil types, storing digital manuals, and logging maintenance records. The author used Notion in the past but found it lacking in functionality.

## 9. [Power of small optimizations](https://news.ycombinator.com/item?id=39318571)

**Total comment counts : 11**

### Summary

 The article discusses the importance of small optimizations that can greatly improve the performance of an application. The author organizes optimizations into a hierarchy, with architecture level optimizations having the greatest impact. They emphasize the need to focus on higher-level optimizations before diving into lower-level ones. The article provides examples of optimizations at both the algorithm and data structure level, such as using hybrid algorithms and specializing algorithms for specific data types. It also suggests source code level optimizations such as avoiding unnecessary memory copying and allocations, changing data layout, and using SIMD instructions or loop unrolling. The author highlights the importance of profiling the application and being curious to explore optimization opportunities. They recommend conducting performance tests as part of the development process to verify optimization results and identify areas for improvement. The article concludes by emphasizing the need to always think about how to improve the performance of the application and to prioritize optimizations based on the most time-consuming parts of the code.

### Top 1 Comment Summary

 The article discusses how 10 years ago, SQLite released a version with numerous microoptimizations that resulted in significant speed improvements. It highlights the importance of not overlooking the impact of small improvements.

### Top 2 Comment Summary

 The article discusses a case in which someone was able to dramatically increase the speed of a scientist's code. The person took one look at the code and instantly achieved a speedup of 14,000 times. The details of how this was accomplished can be found in the linked article.

## 10. [Thinking about high-quality human data](https://news.ycombinator.com/item?id=39321225)

**Total comment counts : 4**

### Summary

 This article discusses the importance of high-quality data in training deep learning models. The majority of labeled data comes from human annotation, which requires attention to detail and careful execution. The article also explores the concept of crowdsourcing and how it has been used for tasks such as evaluating machine translation and creating gold reference translations. Different methods for aggregating annotations, such as majority voting and Cohen's Kappa, are discussed. Additionally, probabilistic graph modeling is mentioned as a way to predict true labels based on factors like task difficulty and rater bias. The article concludes by mentioning the use of EM (Expectation-Maximization) or VB (Variational Bayes) algorithms to maximize the observed data.

### Top 1 Comment Summary

 The NCV (Noisy Cross-Validation) method, developed by Chen et al. in 2019, involves randomly splitting a dataset in half and identifying samples as "clean" if their label matches the predicted label from a model trained on the other half of the data. By repeating this process multiple times, it provides a more detailed indication of the difficulty of specific examples, allowing for manual validation or skipping of challenging parts.

### Top 2 Comment Summary

 The article discusses a guide on "prompt engineering" written by Lilian Weng, which is considered one of the best in the field. The guide is praised for its concise and comprehensive content.

